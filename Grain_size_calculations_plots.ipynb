{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000a4960",
   "metadata": {},
   "source": [
    "# Welcome to the CILAS grain size processing script!\n",
    "\n",
    "### <div style=\"text-align: right\"> Last modified by A.A. Lehrmann 22 November 2024 </div>\n",
    "\n",
    "\n",
    "### The script below will extract .MES data, process the bin sizes, and plot the grain size distribuiton curves\n",
    "\n",
    "### Important instructions before you begin:\n",
    "\n",
    "    1. NEVER edit raw data. Do not delete .MES files. \n",
    "    \n",
    "    2. Make an /CORE_GrainsizeOutput/ folder to put all of your script's outputs, and a /CORE_GrainsizeProcessed/ folder to put your script's processed data\n",
    "\n",
    "    3. When copying folder paths, make sure to remove quotation marks\n",
    "\n",
    "    4. Always add the extension .csv to your output files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9170465",
   "metadata": {},
   "source": [
    "# Convert .MES files to .csv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c911b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def process_mes_file(input_file):\n",
    "    output_rows = []\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        core_name = lines[4].strip()\n",
    "        date = lines[53].strip()\n",
    "\n",
    "        # Process um values\n",
    "        um_values = lines[45:144]\n",
    "        um_values = [float(value.strip()) for value in um_values]\n",
    "\n",
    "        # Process percent values\n",
    "        percent_values = lines[145:244]\n",
    "        percent_values = [float(value.strip()) for value in percent_values]\n",
    "\n",
    "        # Calculate individual percentages\n",
    "        indiv_perc = [percent_values[0]]  # First value remains the same\n",
    "        for i in range(1, len(percent_values)):\n",
    "            indiv_perc.append(percent_values[i] - percent_values[i - 1])\n",
    "\n",
    "        # Zip the data together\n",
    "        for um, percent, indiv_percent in zip(um_values, percent_values, indiv_perc):\n",
    "            output_rows.append([core_name, date, um, percent, indiv_percent])\n",
    "\n",
    "    return output_rows\n",
    "\n",
    "def write_to_csv(output_file, rows):\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Core name\", \"Date\", \"um\", \"percent\", \"indiv perc\"])\n",
    "        writer.writerows(rows)\n",
    "\n",
    "def process_folder(folder_path, output_folder):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.MES'):\n",
    "            input_file = os.path.join(folder_path, filename)\n",
    "            output_file = os.path.join(output_folder, os.path.splitext(filename)[0] + '.csv')\n",
    "            rows = process_mes_file(input_file)\n",
    "            write_to_csv(output_file, rows)\n",
    "            print(f\"Processed {filename} and saved as {output_file}\")\n",
    "\n",
    "# Ask the user for the input and output folder paths\n",
    "input_folder = input(\"Enter the path to the input folder (e.g., /path/to/input_folder): \")\n",
    "output_folder = input(\"Enter the path to the output folder (e.g., /path/to/output_folder): \")\n",
    "\n",
    "# Process the folder\n",
    "process_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097ab4e",
   "metadata": {},
   "source": [
    "# To double check the conversion worked correctly, check the D50 of the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e264d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ask the user for the input file path\n",
    "input_file_path = input(\"Please enter the path to the CSV file: \")\n",
    "\n",
    "# Ask the user for the percentile to calculate\n",
    "percentile = float(input(\"Please enter the percentile to calculate (e.g., 50 for the 50th percentile): \"))\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(input_file_path)\n",
    "\n",
    "# Sort the data by grain size (um)\n",
    "data = data.sort_values('um').reset_index(drop=True)\n",
    "\n",
    "# Calculate the cumulative percentage from the 'percent' column (percent * 100)\n",
    "data['Cumulative (%)'] = data['percent'] * 100  # Multiply percent by 100 to get cumulative %\n",
    "\n",
    "# Print the entire table of grain sizes and their cumulative percentages\n",
    "print(\"Complete Cumulative Percentage Table:\")\n",
    "print(data[['um', 'percent', 'Cumulative (%)']])\n",
    "\n",
    "# Find the grain size at the requested percentile\n",
    "grain_size_percentile = data.loc[data['Cumulative (%)'] >= percentile, 'um']\n",
    "\n",
    "if not grain_size_percentile.empty:\n",
    "    grain_size_value = grain_size_percentile.iloc[0]\n",
    "    print(f\"\\nThe grain size at the {percentile}th percentile is approximately {grain_size_value:.2f} microns.\")\n",
    "else:\n",
    "    print(f\"No grain size found for the {percentile}th percentile.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504788bb",
   "metadata": {},
   "source": [
    "# Individiual sample: Process the grain size data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ecae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cmcrameri.cm as cmc  # Import the cmcrameri colormap\n",
    "\n",
    "# Ask the user for input file path and output file path\n",
    "input_file_path = input(\"Enter the path to the input CSV file: \")  # Prompt user for input file path\n",
    "output_file_path = input(\"Enter the name of the output CSV file (e.g., 'output_file12.csv'): \")  # Prompt user for output file name\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv(input_file_path)\n",
    "\n",
    "# Initialize new columns\n",
    "data['Cumulative (%) Q3'] = 0.0\n",
    "data['Computation'] = 0.0\n",
    "\n",
    "# Calculate Cumulative (%) Q3 for each row\n",
    "for i in range(len(data)):\n",
    "    data.loc[i, 'Cumulative (%) Q3'] = data.loc[i, 'percent'] * 100  # Percent * 100 to get the cumulative percentage\n",
    "\n",
    "# Calculate Computation for each row\n",
    "for i in range(2, len(data)):  # Start from row 3\n",
    "    data.loc[i, 'Computation'] = (data.loc[i, 'Cumulative (%) Q3'] - data.loc[i-1, 'Cumulative (%) Q3']) / np.log(data.loc[i, 'um'] / data.loc[i-1, 'um'])\n",
    "\n",
    "# Calculate Total Computation\n",
    "data['Total Computation'] = data['Computation'].sum()\n",
    "\n",
    "# Calculate Histogram (%) q3\n",
    "data['Histogram (%) q3'] = (data['Computation'] / data['Total Computation']) * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the first axis for Cumulative (%) Q3\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(data['um'], data['Cumulative (%) Q3'], linestyle='-', color=cmc.batlow(0.8), linewidth=2, label='Cumulative (%) Q3')\n",
    "ax1.set_xscale('log')  # Set x-axis to logarithmic scale\n",
    "ax1.set_ylabel('Cumulative (%) Q3', fontsize=14, color=cmc.batlow(0.8))\n",
    "ax1.tick_params(axis='y', labelcolor=cmc.batlow(0.8))\n",
    "\n",
    "# Create a second y-axis for Histogram (%) q3\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(data['um'], data['Histogram (%) q3'], linestyle='-', color=cmc.batlow(0.5), linewidth=2, label='Histogram (%) q3')\n",
    "ax2.set_ylabel('Histogram (%) q3', fontsize=14, color=cmc.batlow(0.5))\n",
    "ax2.tick_params(axis='y', labelcolor=cmc.batlow(0.5))\n",
    "\n",
    "# Common x-axis label and title\n",
    "plt.xlabel('Grain Size (Âµm)', fontsize=14)\n",
    "plt.title('Cumulative (%) Q3 and Histogram (%) q3 vs. Grain Size', fontsize=16)\n",
    "plt.grid(True, which='both', ls='--', linewidth=0.5)\n",
    "\n",
    "# Show legends for both axes\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('cumulative_and_histogram_vs_grain_size.png')  # Save as a PNG file\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "data.to_csv(output_file_path, index=False)\n",
    "print('Calculations completed, plot saved, and data exported to', output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2868cd0",
   "metadata": {},
   "source": [
    "# Plots for a folder of grain size data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cmcrameri.cm as cmc  # Import the cmcrameri colormap\n",
    "\n",
    "# Ask the user for the folder path containing input CSV files and output folder\n",
    "input_folder_path = input(\"Enter the path to the folder containing input CSV files: \").strip()\n",
    "output_folder_path = input(\"Enter the path to the folder to save processed files: \").strip()\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Get all CSV files in the input folder\n",
    "csv_files = [f for f in os.listdir(input_folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Process each CSV file in the folder\n",
    "for file_name in csv_files:\n",
    "    input_file_path = os.path.join(input_folder_path, file_name)\n",
    "    output_file_name = f\"processed_{file_name}\"\n",
    "    output_file_path = os.path.join(output_folder_path, output_file_name)\n",
    "    output_plot_path = os.path.join(output_folder_path, f\"{file_name.replace('.csv', '')}_plot.png\")\n",
    "    \n",
    "    # Read the data\n",
    "    data = pd.read_csv(input_file_path)\n",
    "\n",
    "    # Check if required columns are present\n",
    "    if 'um' in data.columns and 'percent' in data.columns:\n",
    "        # Initialize new columns\n",
    "        data['Cumulative (%) Q3'] = 0.0\n",
    "        data['Computation'] = 0.0\n",
    "\n",
    "        # Calculate Cumulative (%) Q3 for each row\n",
    "        for i in range(len(data)):\n",
    "            data.loc[i, 'Cumulative (%) Q3'] = data.loc[i, 'percent'] * 100  # Percent * 100 to get the cumulative percentage\n",
    "\n",
    "        # Calculate Computation for each row\n",
    "        for i in range(2, len(data)):  # Start from row 3\n",
    "            data.loc[i, 'Computation'] = (data.loc[i, 'Cumulative (%) Q3'] - data.loc[i-1, 'Cumulative (%) Q3']) / np.log(data.loc[i, 'um'] / data.loc[i-1, 'um'])\n",
    "\n",
    "        # Calculate Total Computation\n",
    "        data['Total Computation'] = data['Computation'].sum()\n",
    "\n",
    "        # Calculate Histogram (%) q3\n",
    "        data['Histogram (%) q3'] = (data['Computation'] / data['Total Computation']) * 100\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Create the first axis for Cumulative (%) Q3\n",
    "        ax1 = plt.gca()\n",
    "        ax1.plot(data['um'], data['Cumulative (%) Q3'], linestyle='-', color=cmc.batlow(0.8), linewidth=2, label='Cumulative (%) Q3')\n",
    "        ax1.set_xscale('log')  # Set x-axis to logarithmic scale\n",
    "        ax1.set_ylabel('Cumulative (%) Q3', fontsize=14, color=cmc.batlow(0.8))\n",
    "        ax1.tick_params(axis='y', labelcolor=cmc.batlow(0.8))\n",
    "\n",
    "        # Create a second y-axis for Histogram (%) q3\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(data['um'], data['Histogram (%) q3'], linestyle='-', color=cmc.batlow(0.5), linewidth=2, label='Histogram (%) q3')\n",
    "        ax2.set_ylabel('Histogram (%) q3', fontsize=14, color=cmc.batlow(0.5))\n",
    "        ax2.tick_params(axis='y', labelcolor=cmc.batlow(0.5))\n",
    "\n",
    "        # Common x-axis label and title\n",
    "        plt.xlabel('Grain Size (Âµm)', fontsize=14)\n",
    "        plt.title(f'Cumulative (%) Q3 and Histogram (%) q3 - {file_name}', fontsize=16)\n",
    "        plt.grid(True, which='both', ls='--', linewidth=0.5)\n",
    "\n",
    "        # Show legends for both axes\n",
    "        ax1.legend(loc='upper left')\n",
    "        ax2.legend(loc='upper right')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        plt.savefig(output_plot_path, bbox_inches='tight')  # Save as a PNG file\n",
    "        plt.close()  # Close the plot to avoid memory issues\n",
    "\n",
    "        # Save the updated DataFrame to a new CSV file\n",
    "        data.to_csv(output_file_path, index=False)\n",
    "        print(f\"Processed and saved {file_name} -> CSV and plot saved.\")\n",
    "    else:\n",
    "        print(f\"Skipped {file_name} - missing required columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7b613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6951c7c6",
   "metadata": {},
   "source": [
    "# Plot grain size distribution for one core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efe590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cmcrameri.cm as cmc  # Import the cmcrameri colormap\n",
    "\n",
    "# Ask the user for the input folder path and core name\n",
    "input_folder_path = input(\"Enter the path to the folder containing processed CSV files: \").strip()\n",
    "core_name = input(\"Enter the core name for the title of the graph: \").strip()\n",
    "\n",
    "# Helper function to extract the first number in the last two numbers of the filename\n",
    "def extract_sort_key(file_name):\n",
    "    match = re.search(r\"(\\d+)-(\\d+)\", file_name)  # Matches patterns like '0-1'\n",
    "    if match:\n",
    "        return int(match.group(1))  # Return the first number for sorting\n",
    "    return float('inf')  # Place files without matching pattern at the end\n",
    "\n",
    "# Get and sort the files based on the extracted number\n",
    "processed_files = [f for f in os.listdir(input_folder_path) if f.endswith(\".csv\")]\n",
    "processed_files.sort(key=extract_sort_key)\n",
    "\n",
    "# Initialize a colormap\n",
    "colors = cmc.batlow(np.linspace(0, 1, len(processed_files)))\n",
    "\n",
    "# Initialize the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Counter for assigning colors\n",
    "color_index = 0\n",
    "\n",
    "# Iterate through all processed CSV files in sorted order\n",
    "for file_name in processed_files:\n",
    "    input_file_path = os.path.join(input_folder_path, file_name)\n",
    "    \n",
    "    # Read the processed data\n",
    "    data = pd.read_csv(input_file_path)\n",
    "\n",
    "    # Check if required columns are present\n",
    "    if 'um' in data.columns and 'Histogram (%) q3' in data.columns:\n",
    "        grain_sizes = data['um']\n",
    "        histogram_q3 = data['Histogram (%) q3']\n",
    "\n",
    "        # Plot the histogram on the same graph\n",
    "        plt.plot(grain_sizes, histogram_q3, linestyle='-', linewidth=2, label=file_name, color=colors[color_index])\n",
    "        color_index += 1\n",
    "    else:\n",
    "        print(f\"Skipped {file_name} - missing required columns.\")\n",
    "\n",
    "# Configure the plot\n",
    "plt.xscale('log')  # Set x-axis to logarithmic scale\n",
    "plt.xlabel('Grain Size (Âµm)', fontsize=14)\n",
    "plt.ylabel('Histogram (%) q3', fontsize=14)\n",
    "plt.title(f'Combined Histograms of Grain Size Data for Core {core_name}', fontsize=16)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Place legend below the plot, sorted by filename order\n",
    "plt.legend(\n",
    "    fontsize=10, \n",
    "    title=\"Files\", \n",
    "    title_fontsize=12, \n",
    "    loc='upper center', \n",
    "    bbox_to_anchor=(0.5, -0.15),  # Place legend below the plot\n",
    "    ncol=3  # Adjust the number of columns in the legend\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the combined plot\n",
    "output_plot_path = os.path.join(input_folder_path, f\"combined_histograms_core_{core_name}.png\")\n",
    "plt.savefig(output_plot_path, bbox_inches='tight')  # Save as PNG file\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "print(f\"Combined histogram plot for core {core_name} saved as {output_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe8821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
