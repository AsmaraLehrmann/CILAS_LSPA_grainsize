{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6638b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q4/w7kphmzx3jl2b5pgvmmvn0y80000gn/T/ipykernel_37627/3028112626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0minput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input_path'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output_path'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mprocess_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/q4/w7kphmzx3jl2b5pgvmmvn0y80000gn/T/ipykernel_37627/3028112626.py\u001b[0m in \u001b[0;36mprocess_folder\u001b[0;34m(folder_path, output_folder)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.MES'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_path'"
     ]
    }
   ],
   "source": [
    "## FORMAT .MES FILES TO .CSV FILES ##\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_mes_file(input_file):\n",
    "    output_rows = []\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        core_name = lines[4].strip()\n",
    "        date = lines[53].strip()\n",
    "\n",
    "        # Process um values\n",
    "        um_values = lines[45:144]\n",
    "        um_values = [float(value.strip()) for value in um_values]\n",
    "\n",
    "        # Process percent values\n",
    "        percent_values = lines[145:244]\n",
    "        percent_values = [float(value.strip()) for value in percent_values]\n",
    "\n",
    "        # Calculate individual percentages\n",
    "        indiv_perc = [percent_values[0]]  # First value remains the same\n",
    "        for i in range(1, len(percent_values)):\n",
    "            indiv_perc.append(percent_values[i] - percent_values[i - 1])\n",
    "\n",
    "        # Zip the data together\n",
    "        for um, percent, indiv_percent in zip(um_values, percent_values, indiv_perc):\n",
    "            output_rows.append([core_name, date, um, percent, indiv_percent])\n",
    "\n",
    "    return output_rows\n",
    "\n",
    "def write_to_csv(output_file, rows):\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Core name\", \"Date\", \"um\", \"percent\", \"indiv perc\"])\n",
    "        writer.writerows(rows)\n",
    "\n",
    "def process_folder(folder_path, output_folder):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.MES'):\n",
    "            input_file = os.path.join(folder_path, filename)\n",
    "            output_file = os.path.join(output_folder, os.path.splitext(filename)[0] + '.csv')\n",
    "            rows = process_mes_file(input_file)\n",
    "            write_to_csv(output_file, rows)\n",
    "            print(f\"Processed {filename} and saved as {output_file}\")\n",
    "\n",
    "# Example usage:\n",
    "input_folder = 'input_path'\n",
    "output_folder = 'output_path'\n",
    "process_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bf0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grain size distribution plots of individual samples\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import re\n",
    "import cmcrameri\n",
    "\n",
    "# Path to the folder containing CSV files\n",
    "folder_path = \"folder_path\"\n",
    "\n",
    "# Function to extract numbers from file names\n",
    "def extract_numbers(filename):\n",
    "    return [int(s) for s in re.findall(r'\\d+', filename)]\n",
    "\n",
    "# Initialize lists to store data from all files\n",
    "um_all = []\n",
    "indiv_perc_all = []\n",
    "file_names = []  # Store file names for labels\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(os.path.join(folder_path, filename))\n",
    "        \n",
    "        # Extract the columns of interest\n",
    "        um = data[\"um\"]\n",
    "        indiv_perc = data[\"indiv perc\"]\n",
    "        \n",
    "        # Append data to the lists\n",
    "        um_all.append(um)\n",
    "        indiv_perc_all.append(indiv_perc)\n",
    "        file_names.append(filename)  # Store file name\n",
    "\n",
    "# Sort file names numerically\n",
    "file_names_sorted = sorted(file_names, key=extract_numbers)\n",
    "\n",
    "# Create individual plots for each file\n",
    "for i, (um, indiv_perc, filename) in enumerate(zip(um_all, indiv_perc_all, file_names_sorted)):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    color = cmcrameri.cm.batlow(i / len(file_names_sorted))  # Use cmcrameri color scheme\n",
    "    plt.plot(um, indiv_perc, alpha=0.8, color=color, linewidth=4)\n",
    "    plt.title(f\"Grain size distribution {filename}\")  # Updated title\n",
    "    plt.xlabel('Grain size (µm)')\n",
    "    plt.ylabel('wt %')\n",
    "    plt.grid(True)\n",
    "    plt.xlim(1, 1000)  # Set the minimum and maximum values of the x-axis\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0, 0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(folder_path, f'{filename}_plot.svg'), format='svg')  # Save individual plot\n",
    "\n",
    "plt.show()  # Display combined plot in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c54562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined grain size distribution plot of the core\n",
    "\n",
    "# Function to extract numbers from file names\n",
    "def extract_numbers(filename):\n",
    "    return [int(s) for s in re.findall(r'\\d+', filename)]\n",
    "\n",
    "# Initialize lists to store data from all files\n",
    "um_all = []\n",
    "indiv_perc_all = []\n",
    "file_names = []  # Store file names for labels\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(os.path.join(folder_path, filename))\n",
    "        \n",
    "        # Extract the columns of interest\n",
    "        um = data[\"um\"]\n",
    "        indiv_perc = data[\"indiv perc\"]\n",
    "        \n",
    "        # Append data to the lists\n",
    "        um_all.append(um)\n",
    "        indiv_perc_all.append(indiv_perc)\n",
    "        file_names.append(filename)  # Store file name\n",
    "\n",
    "# Sort file names numerically\n",
    "file_names_sorted = sorted(file_names, key=extract_numbers)\n",
    "\n",
    "# Create a larger figure for combined plot\n",
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "# Create a line plot for each file using cmcrameri's colormap\n",
    "num_files = len(um_all)\n",
    "color_palette = cmcrameri.cm.batlow  # Using 'roma' colormap from cmcrameri\n",
    "for i, (um, indiv_perc, filename) in enumerate(zip(um_all, indiv_perc_all, file_names_sorted)):\n",
    "    color = color_palette(i / num_files)\n",
    "    plt.plot(um, indiv_perc, alpha=1, color=color, label=filename)  # Add label for the file\n",
    "    \n",
    "    # Set x-axis limit to start from 0 and end at 1000\n",
    "    plt.xlim(1, 10000)\n",
    "\n",
    "plt.title('Distribution of \"um\" vs \"indiv perc\"')\n",
    "plt.xlabel('Grain size (µm)')  # Updated x-axis label\n",
    "plt.ylabel('wt %')  # Updated y-axis label\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis to be logarithmic\n",
    "plt.xlim(1, 1000)  # Set the minimum and maximum values of the x-axis\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 0.15)\n",
    "# Display legend outside the plot in numeric order\n",
    "plt.legend(sorted(file_names_sorted, key=lambda x: int(re.search(r'\\d+', x).group())), bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "\n",
    "# Save the combined plot as .svg file\n",
    "plt.savefig(os.path.join(folder_path, 'grainsize_distribution.svg'), format='svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c868305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative weight percent combine plots\n",
    "\n",
    "# Function to extract numbers from file names\n",
    "def extract_numbers(filename):\n",
    "    return [int(s) for s in re.findall(r'\\d+', filename)]\n",
    "\n",
    "# Initialize lists to store data from all files\n",
    "um_all = []\n",
    "cum_perc_all = []\n",
    "file_names = []  # Store file names for labels\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(os.path.join(folder_path, filename))\n",
    "        \n",
    "        # Extract the columns of interest\n",
    "        um = data[\"um\"]\n",
    "        indiv_perc = data[\"indiv perc\"]\n",
    "        \n",
    "        # Ensure the data is sorted by grain size\n",
    "        sorted_indices = np.argsort(um)\n",
    "        um = um.iloc[sorted_indices].reset_index(drop=True)\n",
    "        indiv_perc = indiv_perc.iloc[sorted_indices].reset_index(drop=True)\n",
    "        \n",
    "        # Calculate cumulative percentage\n",
    "        cum_perc = np.cumsum(indiv_perc)\n",
    "        cum_perc = (cum_perc / cum_perc.iloc[-1]) * 100  # Normalize to 100%\n",
    "        \n",
    "        # Append data to the lists\n",
    "        um_all.append(um)\n",
    "        cum_perc_all.append(cum_perc)\n",
    "        file_names.append(filename)  # Store file name\n",
    "\n",
    "# Sort file names numerically\n",
    "file_names_sorted = sorted(file_names, key=extract_numbers)\n",
    "\n",
    "# Create a larger figure for combined plot\n",
    "plt.figure(figsize=(15, 9))\n",
    "\n",
    "# Create a line plot for each file using cmcrameri's colormap\n",
    "num_files = len(um_all)\n",
    "color_palette = cmcrameri.cm.roma  # Using 'roma' colormap from cmcrameri\n",
    "for i, (um, cum_perc, filename) in enumerate(zip(um_all, cum_perc_all, file_names_sorted)):\n",
    "    color = color_palette(i / num_files)\n",
    "    plt.plot(um, cum_perc, linewidth=2, color=color, label=filename)  # Add label for the file\n",
    "    \n",
    "    # Set x-axis limit to start from 1 and end at 1000\n",
    "    plt.xlim(1, 1000)\n",
    "\n",
    "plt.title('Cumulative Distribution of \"um\" vs \"cumulative perc\"')\n",
    "plt.xlabel('Grain size (µm)')  # Updated x-axis label\n",
    "plt.ylabel('Cumulative wt %')  # Updated y-axis label\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis to be logarithmic\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 100)  # Assuming cumulative percentage goes from 0 to 100\n",
    "\n",
    "# Display legend outside the plot in numeric order\n",
    "plt.legend(sorted(file_names_sorted, key=lambda x: int(re.search(r'\\d+', x).group())), bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "\n",
    "# Save the combined plot as .png file with transparency\n",
    "plt.savefig(os.path.join(folder_path, 'cumulative_grainsize_distribution.png'), format='png', transparent=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee43d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative grain size distribution curves\n",
    "\n",
    "for i, (um, cum_perc, filename) in enumerate(zip(um_all, cum_perc_all, file_names_sorted)):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    color = color_palette(i / num_files)  # Use cmcrameri colors for individual plots\n",
    "    plt.plot(um, cum_perc, linewidth=2, color=color)\n",
    "    plt.title(f\"Cumulative Grain size distribution {filename}\")  # Updated title\n",
    "    plt.xlabel('Grain size (µm)')\n",
    "    plt.ylabel('Cumulative wt %')\n",
    "    plt.grid(True)\n",
    "    plt.xlim(1, 1000)  # Set the minimum and maximum values of the x-axis\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(folder_path, f'{filename}_cumulative_plot.png'), format='png', transparent=True)  # Save individual plot\n",
    "\n",
    "    plt.show()  # Display individual plot in Python\n",
    "\n",
    "plt.show()  # Display combined plot in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import cmcrameri\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract lower and upper depths from file name\n",
    "def extract_depths(file_name):\n",
    "    depths_str = file_name.split('_')[-1].split('-')\n",
    "    lower_depth = float(depths_str[0])\n",
    "    upper_depth = float(depths_str[1])\n",
    "    return lower_depth, upper_depth\n",
    "\n",
    "# Function to read data from multiple CSV files\n",
    "def read_multiple_data(directory):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "            lower_depth, upper_depth = extract_depths(os.path.basename(file_path).split('.')[0])  # Extract depths from file name\n",
    "            data['Lower Depth'] = lower_depth\n",
    "            data['Upper Depth'] = upper_depth\n",
    "            all_data.append(data)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def plot_combined_data(combined_data):\n",
    "    fig, ax1 = plt.subplots(figsize=(2, 8))  # Adjust the width and height (in inches) as needed\n",
    "\n",
    "    # Plot weight percent\n",
    "    cmap = cmcrameri.cm.batlow  # Using the 'batlow' colormap from cmcrameri\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=0.1)  # Update the range to 0-0.1 for weight percent\n",
    "    \n",
    "    # Filter out NaN values\n",
    "    combined_data_filtered = combined_data.dropna(subset=['um', 'Lower Depth', 'indiv perc'])\n",
    "\n",
    "    sc = ax1.scatter(combined_data_filtered['um'], combined_data_filtered['Lower Depth'], c=combined_data_filtered['indiv perc'], cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar(sc, ax=ax1, label='Weight Percent')\n",
    "\n",
    "    # Reverse the y-axis\n",
    "    ax1.set_ylim(ax1.get_ylim()[::-1])\n",
    "\n",
    "    # Set x-axis to log scale with range from 1 to 1000\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_xlim(1, 1000)  # Set the x-axis limit from 1 to 1000\n",
    "\n",
    "    # Set labels and titles\n",
    "    ax1.set_xlabel('Grain Size (um)')\n",
    "    ax1.set_ylabel('Depth (cm)')\n",
    "    ax1.set_title('Combined Grain Size Distribution')\n",
    "\n",
    "    # Group data by Lower Depth and find the micron with the highest weight percent\n",
    "    max_um_per_depth = combined_data.groupby('Lower Depth').apply(lambda x: x.loc[x['indiv perc'].idxmax()]['um'])\n",
    "\n",
    "    # Plot the result\n",
    "    # Plot the result\n",
    "    ax1.plot(max_um_per_depth.values, max_um_per_depth.index, color='gray', linestyle='-')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Directory containing CSV files\n",
    "directory = \"folder path\"\n",
    "\n",
    "# Read and combine data from multiple CSV files\n",
    "combined_data = read_multiple_data(directory)\n",
    "\n",
    "# Plot combined data\n",
    "plot_combined_data(combined_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6385c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf604911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
